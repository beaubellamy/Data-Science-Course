{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pFHxIL9yv07"
   },
   "source": [
    "![image.png](https://i.imgur.com/1WaY7aA.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5bT8r4RGyv1A"
   },
   "source": [
    "#  Data Science and AI\n",
    "## Demo: CNN with Keras\n",
    "INSTRUCTIONS:\n",
    "- Run the cells\n",
    "- Observe and understand the results\n",
    "- Answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dfgYO-oyv1D"
   },
   "source": [
    "## Faces classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TH3F0aLlyv1H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmF9-C-syv1Q"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0DhL5fvqyv1T"
   },
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFuJDWijyv1Y"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpYq76vyyv1a"
   },
   "outputs": [],
   "source": [
    "# The faces dataset\n",
    "faces = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnadpkG2yv1f"
   },
   "outputs": [],
   "source": [
    "print(faces.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wO-oI0WUyv1k"
   },
   "outputs": [],
   "source": [
    "id = np.random.randint(len(faces.target))\n",
    "plt.figure(figsize = (3, 3))\n",
    "plt.imshow(faces.images[id], cmap = 'gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_3rwC2rdyv1n"
   },
   "outputs": [],
   "source": [
    "# Prepare input data\n",
    "# input\n",
    "X = faces.images\n",
    "img_rows, img_cols = X[0].shape\n",
    "X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# output\n",
    "target = faces.target.astype(np.uint8)\n",
    "\n",
    "# Convert the target to categorical\n",
    "y = to_categorical(\n",
    "    target,\n",
    "    num_classes = len(set(target)),\n",
    "    dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hEIZT0Pyv1q"
   },
   "outputs": [],
   "source": [
    "filter = []\n",
    "# run in blocks of 10\n",
    "for i in range(len(target) // 10):\n",
    "    s = set()\n",
    "    while len(s) < 2:\n",
    "        s = set(np.random.randint(0, 10, 2, dtype = np.int8))\n",
    "    a = [x in s for x in range(10)]\n",
    "    filter.append(a)\n",
    "test = np.array(filter).flatten()\n",
    "train = np.array([not t for t in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAwmwl9fyv1s"
   },
   "outputs": [],
   "source": [
    "X_train = X[train].copy()\n",
    "X_test  = X[test].copy()\n",
    "y_train = y[train].copy()\n",
    "y_test  = y[test].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2P9oGZCxyv1t"
   },
   "outputs": [],
   "source": [
    "# Set up the model architecture\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMv2DgJtyv1v"
   },
   "outputs": [],
   "source": [
    "# Add a convolutional layer\n",
    "model.add(Conv2D(60,\n",
    "                 kernel_size = 4,\n",
    "                 activation = 'relu',\n",
    "                 data_format = 'channels_last',\n",
    "                 padding = 'valid',\n",
    "                 input_shape = (img_rows, img_cols, 1)))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(30,\n",
    "                 kernel_size = 2,\n",
    "                 activation = 'relu'))\n",
    "\n",
    "# Flatten the output of the convolutional layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add an output layer for the 3 categories\n",
    "model.add(Dense(len(set(target)),\n",
    "                activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAK8acr9yv1x",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DkcUhjmyv11"
   },
   "outputs": [],
   "source": [
    "# Compile the model \n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OCxnEJOyv12"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the model on a training set\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs = 9,\n",
    "    batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENovdR5_yv15"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuw-Lnpuyv17",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size = 10)\n",
    "print('\\nTest loss: %.6f, Test accuracy: %.6f' % tuple(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZkGlsB2yv19"
   },
   "outputs": [],
   "source": [
    "def print_cm(cm):\n",
    "    d_size = max(len('%d' % cm.max()), len('%d' % cm.shape[1]))\n",
    "    if min(cm.shape) > 10: # make sparse\n",
    "        print('Sparse Matrix (*=diagonal)')\n",
    "        fmt_r = 'r%%0%dd' % d_size\n",
    "        fmt_c = ', c%%0%dd%%s= %%%dd' % (d_size, d_size)\n",
    "        for i in range(cm.shape[0]):\n",
    "            s = fmt_r % i\n",
    "            for j in range(cm.shape[1]):\n",
    "                if cm[i, j] > 0:\n",
    "                    s += fmt_c % (j, '*' if i == j else ' ', cm[i, j])\n",
    "            print(s)\n",
    "    else: # make dense\n",
    "        c = '%%%dd ' % d_size\n",
    "        s = '%s| ' % (' ' * d_size)\n",
    "        s += ''.join([c % i for i in range(len(cm[0]))])\n",
    "        print(s)\n",
    "        print('-' * len(s))\n",
    "        for i, r in enumerate(cm):\n",
    "            s = '%2d| ' % i\n",
    "            s += c * len(r)\n",
    "            print(s % tuple(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Jz1anYwyv1-",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test_target = np.array([x.argmax() for x in y_test])\n",
    "cm = confusion_matrix(y_test_target, predictions)\n",
    "print_cm(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ngmNXvOyv2C"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (18, 6))\n",
    "fig.subplots_adjust(left = 0.02, right = 0.98, wspace = 0.2)\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "ax[0].plot(model.history.history['acc'])\n",
    "ax[0].plot(model.history.history['val_acc'])\n",
    "ax[0].set_title('Model accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "ax[1].plot(model.history.history['loss'])\n",
    "ax[1].plot(model.history.history['val_loss'])\n",
    "ax[1].set_title('Model loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9V0zAzJyv2E"
   },
   "outputs": [],
   "source": [
    "def implot2(im1, im2, id):\n",
    "    t1 = y_test[id].argmax()\n",
    "    t2 = predictions[id]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (6, 3))\n",
    "    fig.subplots_adjust(left = 0.02, right = 0.98, top = 0.85, wspace = 0.2)\n",
    "    fig.suptitle('Prediction %d' % id, fontsize = 12, fontweight = 'bold')\n",
    "\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "    # original image\n",
    "    ax[0].imshow(im1, cmap = 'gray')\n",
    "    ax[0].set_title('Original id: %d' % t1)\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "\n",
    "    # convoluted image\n",
    "    ax[1].imshow(im2, cmap = 'gray')\n",
    "    ax[1].set_title('Test id: %d' % t2)\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9x2SbfxNyv2G"
   },
   "outputs": [],
   "source": [
    "def pick_test_image(pid):\n",
    "    # pick the prediction\n",
    "    ppid = predictions[pid]\n",
    "    # find the corresponding image\n",
    "    j = -1\n",
    "    for ipid in range(test.shape[0]):\n",
    "        if test[ipid]:\n",
    "            j += 1\n",
    "        if j == pid:\n",
    "            break\n",
    "    return X[ipid].reshape(img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWkU7UEGyv2J"
   },
   "outputs": [],
   "source": [
    "def pick_train_image(ppid):\n",
    "    oid = np.array([a.argmax() == ppid for a in y_train]).argmax()\n",
    "    poid = y_train[oid].argmax()\n",
    "    j = -1\n",
    "    for ioid in range(train.shape[0]):\n",
    "        if train[ioid]:\n",
    "            j += 1\n",
    "        if j == oid:\n",
    "            break\n",
    "    return X[ioid].reshape(img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEnS6712yv2K"
   },
   "outputs": [],
   "source": [
    "def compare_images(id):\n",
    "    XTest = pick_test_image(id)\n",
    "    XTrain = pick_train_image(predictions[id])\n",
    "    implot2(XTrain, XTest, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZEUyv-UAyv2M"
   },
   "outputs": [],
   "source": [
    "# compare one\n",
    "id = np.random.randint(len(predictions))\n",
    "compare_images(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_o2EPD7syv2N",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare ten\n",
    "ids = np.random.randint(len(predictions), size = 10)\n",
    "for id in ids:\n",
    "    compare_images(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS5Tc4z9FoYy"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxI2We9OFpfs"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81DoNxN1FqGN"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2019 Data Science Institute of Australia\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Demo-10-Keras_CNNs.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYvQOebqLcfM"
   },
   "source": [
    "![alt text](https://i.imgur.com/1WaY7aA.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JWvLBewLcfP"
   },
   "source": [
    "# Data Science and AI\n",
    "## Demo 9.6: Sentiment Analysis\n",
    "INSTRUCTIONS:\n",
    "- Run the cells\n",
    "- Observe and understand the results\n",
    "- Answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HbhmKC6NLcfS"
   },
   "source": [
    "Based on the video tutorial **Text Classification with Machine Learning,SpaCy and Scikit(Sentiment Analysis)** by **Jesse E. Agbe (JCharis)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnuAMgbhLcfV"
   },
   "source": [
    "## Data Source: UCI\n",
    "### UCI - Machine Learning Repository\n",
    "- Center for Machine Learning and Intelligent Systems\n",
    "\n",
    "The [**UCI Machine Learning Repository**](http://archive.ics.uci.edu/ml/about.html) is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms.\n",
    "\n",
    "### Dataset\n",
    "- [Sentiment Labelled Sentences Data Set](http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)\n",
    "\n",
    "### Abstract\n",
    "The dataset contains sentences labelled with positive or negative sentiment.\n",
    "\n",
    "- Data Set Characteristics: Text\n",
    "- Number of Instances: 3000\n",
    "- Area: N/A\n",
    "- Attribute Characteristics: N/A\n",
    "- Number of Attributes: N/A\n",
    "- Date Donated: 2015-05-30\n",
    "- Associated Tasks: Classification\n",
    "- Missing Values? N/A\n",
    "- Number of Web Hits: 102584\n",
    "\n",
    "### Source\n",
    "Dimitrios Kotzias dkotzias '@' ics.uci.edu\n",
    "\n",
    "### Data Set Information\n",
    "This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015\n",
    "\n",
    "Please cite the paper if you want to use it :)\n",
    "\n",
    "It contains sentences labelled with positive or negative sentiment.\n",
    "\n",
    "### Format\n",
    "sentence &lt;tab&gt; score &lt;newline&gt;\n",
    "\n",
    "### Details\n",
    "Score is either 1 (for positive) or 0 (for negative)\n",
    "\n",
    "The sentences come from three different websites/fields:\n",
    "- imdb.com\n",
    "- amazon.com\n",
    "- yelp.com\n",
    "\n",
    "For each website, there exist **500 positive** and **500 negative** sentences. Those were selected randomly for larger datasets of reviews.\n",
    "\n",
    "We attempted to select sentences that have a clearly positive or negative connotaton, the goal was for no neutral sentences to be selected.\n",
    "\n",
    "For the full datasets look:\n",
    "\n",
    "- **imdb**: Maas et. al., 2011 _Learning word vectors for sentiment analysis_\n",
    "- **amazon**: McAuley et. al., 2013 _Hidden factors and hidden topics: Understanding rating dimensions with review text_\n",
    "- **yelp**: [Yelp dataset challenge](http://www.yelp.com/dataset_challenge)\n",
    "\n",
    "\n",
    "### Attribute Information\n",
    "The attributes are text sentences, extracted from reviews of products, movies, and restaurants\n",
    "\n",
    "### Relevant Papers\n",
    "**From Group to Individual Labels using Deep Features**, Kotzias et. al,. KDD 2015\n",
    "\n",
    "### Citation Request\n",
    "**From Group to Individual Labels using Deep Features**, Kotzias et. al,. KDD 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abNvVWdlLcfW"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:08:40.089698Z",
     "start_time": "2019-06-17T03:08:36.408536Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4BJWjM0zLcfZ"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import pandas as pd\n",
    "\n",
    "import regex as re\n",
    "import spacy\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dzzk6JdcLcfh"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:10:07.311394Z",
     "start_time": "2019-06-17T03:10:07.281474Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GZUWhcCuLcfi"
   },
   "outputs": [],
   "source": [
    "# source is separated by <tab>s and has no headers\n",
    "df_yelp = pd.read_csv('../../DATA/yelp_labelled.txt', header = None, sep = '\\t')\n",
    "df_imdb = pd.read_csv('../../DATA/imdb_labelled_fixed.txt', header = None, sep = '\\t') # New file without double quotes\n",
    "df_amazon = pd.read_csv('../../DATA/amazon_cells_labelled.txt', header = None, sep = '\\t')\n",
    "dfs = {'yelp': df_yelp, 'imdb': df_imdb, 'amazon': df_amazon}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pwa3MBrwLcfo"
   },
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:10:09.333113Z",
     "start_time": "2019-06-17T03:10:09.291221Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NddGh-EQLcfq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: yelp [1000 row(s) x 2 col(s)]\n",
      "                                                text  sentiment source\n",
      "0                           Wow... Loved this place.          1   yelp\n",
      "1                                 Crust is not good.          0   yelp\n",
      "2          Not tasty and the texture was just nasty.          0   yelp\n",
      "3  Stopped by during the late May bank holiday of...          1   yelp\n",
      "4  The selection on the menu was great and so wer...          1   yelp\n",
      "---------------------------------------------------------------------------\n",
      "Dataset: imdb [1000 row(s) x 2 col(s)]\n",
      "                                                text  sentiment source\n",
      "0  A very, very, very slow-moving, aimless movie ...          0   imdb\n",
      "1  Not sure who was more lost - the flat characte...          0   imdb\n",
      "2  Attempting artiness with black & white and cle...          0   imdb\n",
      "3       Very little music or anything to speak of.            0   imdb\n",
      "4  The best scene in the movie was when Gerardo i...          1   imdb\n",
      "---------------------------------------------------------------------------\n",
      "Dataset: amazon [1000 row(s) x 2 col(s)]\n",
      "                                                text  sentiment  source\n",
      "0  So there is no way for me to plug it in here i...          0  amazon\n",
      "1                        Good case, Excellent value.          1  amazon\n",
      "2                             Great for the jawbone.          1  amazon\n",
      "3  Tied to charger for conversations lasting more...          0  amazon\n",
      "4                                  The mic is great.          1  amazon\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# - assign column names\n",
    "# - add the data source\n",
    "# - check the data\n",
    "for ds in dfs.keys():\n",
    "    print('Dataset: %s [%d row(s) x %d col(s)]' % (ds, dfs[ds].shape[0], dfs[ds].shape[1]))\n",
    "    dfs[ds].columns = ['text', 'sentiment']\n",
    "    dfs[ds]['source'] = ds\n",
    "    print(dfs[ds].head())\n",
    "    print('-' * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nj3TftXLcfs"
   },
   "source": [
    "## Note:\n",
    "All the datasets should have _1000_ records each. The **imbd** dataset only shows _748_ records!!\n",
    "\n",
    "**Why**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:10:12.175735Z",
     "start_time": "2019-06-17T03:10:12.162765Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "w91dgJrNLcft"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       82.188000\n",
       "std        56.244966\n",
       "min         7.000000\n",
       "25%        41.000000\n",
       "50%        68.000000\n",
       "75%       108.250000\n",
       "max       479.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(df_imdb[10:30]['text'].apply(len))\n",
    "# check the distribution of lenght of texts\n",
    "pd.Series(df_imdb['text'].apply(len)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tvl0cI8Lcfx"
   },
   "source": [
    "The mean of text's len is _110_ while the largest is _7944_ characters long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:10:14.143539Z",
     "start_time": "2019-06-17T03:10:14.136557Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Sjg5gm8VLcfy"
   },
   "outputs": [],
   "source": [
    "l = df_imdb['text'].map(len)\n",
    "for i, s in zip(l.index, l):\n",
    "    if s > 1000:\n",
    "        print('index: %3d, size: %4d\\ntext |%s|\\n' % (i, s, df_imdb.iloc[i]['text']))\n",
    "        print('-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJ7AcyhNLcf1"
   },
   "source": [
    "The source data from imdb har umbalanced double quotes (\").\n",
    "\n",
    "As the file is small, it can be edited manually.\n",
    "\n",
    "In a Unix/Unix like system, it can be fixed with the command:\n",
    "\n",
    "    cat imdb_labelled.txt | tr -d '\"' > imdb_labelled_fixed.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "meEtfGfELcf4"
   },
   "source": [
    "## Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:10:21.575187Z",
     "start_time": "2019-06-17T03:10:21.566186Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SSqaJf1eLcf5"
   },
   "outputs": [],
   "source": [
    "df = pd.concat(dfs.values(), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:10:21.927047Z",
     "start_time": "2019-06-17T03:10:21.895127Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "PmqNgVgRLcf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: All [3000 row(s) x 3 col(s)]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 3 columns):\n",
      "text         3000 non-null object\n",
      "sentiment    3000 non-null int64\n",
      "source       3000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 70.4+ KB\n",
      "None\n",
      "                                                   text  sentiment  source\n",
      "1345                          Babie Bop is very cute.            1    imdb\n",
      "189   Also were served hot bread and butter, and hom...          1    yelp\n",
      "2259             Great for using with your home stereo.          1  amazon\n",
      "2854                            Comfortable in my hand.          1  amazon\n",
      "2850                                It looks very nice.          1  amazon\n",
      "1704                 DELETE this film from your mind!            0    imdb\n",
      "1574  Aside from it's terrible lead, this film has l...          0    imdb\n",
      "620     I had the chicken Pho and it tasted very bland.          0    yelp\n",
      "1392  I think it was Robert Ryans best film, because...          1    imdb\n",
      "421   On the ground, right next to our table was a l...          0    yelp\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Dataset: %s [%d row(s) x %d col(s)]\\n' % ('All', df.shape[0], df.shape[1]))\n",
    "print(df.info())\n",
    "print(df.sample(10))\n",
    "print('-' * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBIFtbMALcf8"
   },
   "source": [
    "## Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:10:22.510905Z",
     "start_time": "2019-06-17T03:10:22.474003Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "n8OLkaALLcf9",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/sentiments.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-dd6edd757486>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/sentiments.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1522\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1524\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1635\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m   1636\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m   1638\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/sentiments.csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv('../..data/sentiments.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bzA4FQsPLcgA"
   },
   "source": [
    "## Prepare the stage\n",
    "- Load spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVMTSDYQLcgB"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YguMrtDuLcgD"
   },
   "source": [
    "## Prepare the text\n",
    "All the text handling and preparation concerned with the changes and modifications from the raw source text to a format that will be used for the actual processing, things like:\n",
    "- handle encoding\n",
    "- handle extraneous and international charaters\n",
    "- handle simbols\n",
    "- handle metadata and embeded information\n",
    "- handle repetitions (such multiple spaces or newlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlsKSvonLcgD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # reduce multiple spaces and newlines to only one\n",
    "    text = re.sub(r'(\\s\\s+|\\n\\n+)', r'\\1', text)\n",
    "    # remove double quotes\n",
    "    text = re.sub(r'\"', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upPa3YmmLcgF"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "za_6vt3MLcgH"
   },
   "source": [
    "## Work the text\n",
    "Concern with the meaning and the substance of the content to extract actual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sh_uDWcCLcgI"
   },
   "outputs": [],
   "source": [
    "def convert_text(text):\n",
    "    sent = nlp(text)\n",
    "    ents = {x.text: x for x in sent.ents}\n",
    "    tokens = []\n",
    "    for w in sent:\n",
    "        if w.is_stop or w.is_punct:\n",
    "            continue\n",
    "        if w.text in ents:\n",
    "            tokens.append(w.text)\n",
    "        else:\n",
    "            tokens.append(w.lemma_.lower())\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vDv55U1LcgK"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df['short'] = df['text'].apply(convert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "faiuJfunLcgM"
   },
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbwjijVyLcgP"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eJZpD903LcgQ"
   },
   "outputs": [],
   "source": [
    "# helper function to show results and charts\n",
    "def show_summary_report(actual, prediction):\n",
    "\n",
    "    if isinstance(actual, pd.Series):\n",
    "        actual = actual.values\n",
    "    if actual.dtype.name == 'object':\n",
    "        actual = actual.astype(int)\n",
    "    if prediction.dtype.name == 'object':\n",
    "        prediction = prediction.astype(int)\n",
    "\n",
    "    accuracy_ = accuracy_score(actual, prediction)\n",
    "    precision_ = precision_score(actual, prediction)\n",
    "    recall_ = recall_score(actual, prediction)\n",
    "    roc_auc_ = roc_auc_score(actual, prediction)\n",
    "\n",
    "    print('Accuracy : %.4f [TP / N] Proportion of predicted labels that match the true labels. Best: 1, Worst: 0' % accuracy_)\n",
    "    print('Precision: %.4f [TP / (TP + FP)] Not to label a negative sample as positive.        Best: 1, Worst: 0' % precision_)\n",
    "    print('Recall   : %.4f [TP / (TP + FN)] Find all the positive samples.                     Best: 1, Worst: 0' % recall_)\n",
    "    print('ROC AUC  : %.4f                                                                     Best: 1, Worst: < 0.5' % roc_auc_)\n",
    "    print('-' * 107)\n",
    "    print('TP: True Positives, FP: False Positives, TN: True Negatives, FN: False Negatives, N: Number of samples')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    mat = confusion_matrix(actual, prediction)\n",
    "\n",
    "    # Precision/Recall\n",
    "    precision, recall, _ = precision_recall_curve(actual, prediction)\n",
    "    average_precision = average_precision_score(actual, prediction)\n",
    "    \n",
    "    # Compute ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(actual, prediction)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (18, 6))\n",
    "    fig.subplots_adjust(left = 0.02, right = 0.98, wspace = 0.2)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    sns.heatmap(mat.T, square = True, annot = True, fmt = 'd', cbar = False, cmap = 'Blues', ax = ax[0])\n",
    "\n",
    "    ax[0].set_title('Confusion Matrix')\n",
    "    ax[0].set_xlabel('True label')\n",
    "    ax[0].set_ylabel('Predicted label')\n",
    "    \n",
    "    # Precision/Recall\n",
    "    step_kwargs = {'step': 'post'}\n",
    "    ax[1].step(recall, precision, color = 'b', alpha = 0.2, where = 'post')\n",
    "    ax[1].fill_between(recall, precision, alpha = 0.2, color = 'b', **step_kwargs)\n",
    "    ax[1].set_ylim([0.0, 1.0])\n",
    "    ax[1].set_xlim([0.0, 1.0])\n",
    "    ax[1].set_xlabel('Recall')\n",
    "    ax[1].set_ylabel('Precision')\n",
    "    ax[1].set_title('2-class Precision-Recall curve')\n",
    "\n",
    "    # ROC\n",
    "    ax[2].plot(fpr, tpr, color = 'darkorange', lw = 2, label = 'ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    ax[2].plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--')\n",
    "    ax[2].set_xlim([0.0, 1.0])\n",
    "    ax[2].set_ylim([0.0, 1.0])\n",
    "    ax[2].set_xlabel('False Positive Rate')\n",
    "    ax[2].set_ylabel('True Positive Rate')\n",
    "    ax[2].set_title('Receiver Operating Characteristic')\n",
    "    ax[2].legend(loc = 'lower right')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return (accuracy_, precision_, recall_, roc_auc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hj2aoBqqLcgV"
   },
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "X = df['short']\n",
    "y = df['sentiment']\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yr_VmeNMLcgY"
   },
   "source": [
    "## Use Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rhd__LD6LcgZ"
   },
   "outputs": [],
   "source": [
    "# create a matrix of word counts from the text\n",
    "counts = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23CpVgPxLcgb"
   },
   "outputs": [],
   "source": [
    "# do the actual counting\n",
    "A = counts.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_rue57RLcgd"
   },
   "outputs": [],
   "source": [
    "# create a classifier using SVC\n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lou4xDLmLcgh"
   },
   "outputs": [],
   "source": [
    "# train the classifier with the training data\n",
    "classifier.fit(A.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inkg1KTiLcgi"
   },
   "outputs": [],
   "source": [
    "# do the transformation for the test data\n",
    "# NOTE: use `transform()` instead of `fit_transform()`\n",
    "B = counts.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dg-HpdJ0Lcgk"
   },
   "outputs": [],
   "source": [
    "# make predictions based on the test data\n",
    "predictions = classifier.predict(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0HJn9qhLcgm"
   },
   "outputs": [],
   "source": [
    "# check the accuracy\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-Ia6a8ULcgn"
   },
   "source": [
    "## Repeat using TF-IDF\n",
    "TF-IDF = Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Tg1dwSpLcgo"
   },
   "outputs": [],
   "source": [
    "# create a matrix of word counts from the text\n",
    "# use TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "# do the actual counting\n",
    "A = tfidf.fit_transform(X_train, y_train)\n",
    "\n",
    "# train the classifier with the training data\n",
    "classifier.fit(A.toarray(), y_train)\n",
    "\n",
    "# do the transformation for the test data\n",
    "# NOTE: use `transform()` instead of `fit_transform()`\n",
    "B = tfidf.transform(X_test)\n",
    "\n",
    "# make predictions based on the test data\n",
    "predictions = classifier.predict(B)\n",
    "\n",
    "# check the accuracy\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O5PTu402Lcgq"
   },
   "source": [
    "## Repeating it all for comparision\n",
    "Repeating the whole lot in one big block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_98CzdfPLcgq"
   },
   "outputs": [],
   "source": [
    "# Keep the results in a dataframe\n",
    "results = pd.DataFrame(columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'ROC_AUC'])\n",
    "\n",
    "models = ['Count', 'TF-IDX']\n",
    "for i, m in enumerate([CountVectorizer(), TfidfVectorizer()]):\n",
    "    print('*' * (len(models[i]) + 4))\n",
    "    print('* %s *' % models[i])\n",
    "    print('*' * (len(models[i]) + 4))\n",
    "    \n",
    "    # create a matrix of word counts from the text\n",
    "    # use TF-IDF\n",
    "    counts = m\n",
    "    # do the actual counting\n",
    "    A = counts.fit_transform(X_train, y_train)\n",
    "\n",
    "    # create a classifier using SVC\n",
    "    classifier = LinearSVC()\n",
    "\n",
    "    # train the classifier with the training data\n",
    "    classifier.fit(A.toarray(), y_train)\n",
    "\n",
    "    # do the transformation for the test data\n",
    "    # NOTE: use `transform()` instead of `fit_transform()`\n",
    "    B = counts.transform(X_test)\n",
    "\n",
    "    # make predictions based on the test data\n",
    "    predictions = classifier.predict(B)\n",
    "\n",
    "    # show the report\n",
    "    accuracy_, precision_, recall_, roc_auc_ = show_summary_report(y_test, predictions)\n",
    "    # keep the results\n",
    "    results.loc[i] = {'Model': models[i], \n",
    "                      'Accuracy': accuracy_, \n",
    "                      'Precision': precision_,\n",
    "                      'Recall': recall_,\n",
    "                      'ROC_AUC': roc_auc_}\n",
    "    print()\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS5Tc4z9FoYy"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxI2We9OFpfs"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81DoNxN1FqGN"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2019 Data Science Institute of Australia\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Demo-9_6.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

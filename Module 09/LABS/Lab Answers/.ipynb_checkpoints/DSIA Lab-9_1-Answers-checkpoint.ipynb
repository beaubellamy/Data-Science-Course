{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkKr644DL-tU"
   },
   "source": [
    "![image.png](https://i.imgur.com/1WaY7aA.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9g6qykXJL-tX"
   },
   "source": [
    "# Data Science and AI\n",
    "## Lab 9.1: Regular Expressions\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "- Run the cells\n",
    "- Observe and understand the results\n",
    "- Answer the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:06:57.690358Z",
     "start_time": "2019-06-17T03:06:57.682380Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JnKwEY-EL-ta"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPLQxm2SL-tj"
   },
   "source": [
    "## 1. Extract the `user id`, `domain name` and `suffix` from the following email addresses\n",
    "**Hint**: Use groups with `()`. There are more sophisticated patterns for matching the email domain and suffix. This is just one version of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:07:00.274447Z",
     "start_time": "2019-06-17T03:07:00.257491Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "BqCoNp9jL-tl"
   },
   "outputs": [],
   "source": [
    "emails = '''zuck26@facebook.com\n",
    "page33@google.com\n",
    "jeff42@amazon.com'''\n",
    "\n",
    "desired_output = [\n",
    "    ('zuck26', 'facebook', 'com'),\n",
    "    ('page33', 'google', 'com'),\n",
    "    ('jeff42', 'amazon', 'com')\n",
    "]\n",
    "\n",
    "pattern = r'(\\w+)@([A-Z0-9]+)\\.([A-Z]{2,4})'\n",
    "flags = re.IGNORECASE\n",
    "\n",
    "output = re.findall(pattern, emails, flags = flags)\n",
    "\n",
    "assert output == desired_output, 'Not equal!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FrpTl5k8L-tq"
   },
   "source": [
    "## 2. Retrieve all the words starting with 'b' or 'B' from the following text\n",
    "`\\b` mandates the left of `B` is a word boundary, effectively requiring the word to start with `B`.\n",
    "\n",
    "Setting `flags` arg to `re.IGNORECASE` makes the pattern case insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:07:02.411455Z",
     "start_time": "2019-06-17T03:07:02.391508Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3WfDfuN6L-tr"
   },
   "outputs": [],
   "source": [
    "text = 'Betty bought a bit of butter, But the butter was so bitter, So she bought some better butter, To make the bitter butter better.'\n",
    "\n",
    "desired_output = [\n",
    "    'Betty', 'bought', 'bit', 'butter', 'But', \n",
    "    'butter', 'bitter', 'bought', 'better', \n",
    "    'butter', 'bitter', 'butter', 'better'\n",
    "]\n",
    "\n",
    "pattern = r'\\bB\\w+'\n",
    "flags = re.IGNORECASE\n",
    "\n",
    "output = re.findall(pattern, text, flags = flags)\n",
    "\n",
    "assert output == desired_output, 'Not equal!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ud6omzt0L-tv"
   },
   "source": [
    "## 3. Split the following irregular sentence into words\n",
    "Add more delimiters into the pattern as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:07:04.529857Z",
     "start_time": "2019-06-17T03:07:04.520881Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "oOKdzlhYL-tw"
   },
   "outputs": [],
   "source": [
    "sentence = 'A, very   very; irregular_sentence'\n",
    "\n",
    "desired_output = 'A very very irregular sentence'\n",
    "\n",
    "pattern = r'[;,\\s_]+'\n",
    "\n",
    "output = ' '.join(re.split(pattern, sentence))\n",
    "\n",
    "assert output == desired_output, 'Not equal!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81L2SRjEL-t0"
   },
   "source": [
    "## 4. Clean up the following tweet so that it contains only the user’s message\n",
    "That is, remove all URLs, hashtags, mentions, punctuations, RTs and CCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:07:06.665300Z",
     "start_time": "2019-06-17T03:07:06.622398Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ENU4hR7vL-t0"
   },
   "outputs": [],
   "source": [
    "tweet = 'Good advice! RT @TheNextWeb: What I would do differently if I was learning to code today http://t.co/lbwej0pxOd cc: @garybernhardt #rstats'\n",
    "\n",
    "desired_output = 'Good advice What I would do differently if I was learning to code today'\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # remove URLs\n",
    "    tweet = re.sub(r'http\\S+\\s*', '', tweet)\n",
    "    # remove RT and cc\n",
    "    tweet = re.sub(r'RT|cc', '', tweet)\n",
    "    # remove hashtags\n",
    "    tweet = re.sub(r'#\\S+', '', tweet)\n",
    "    # remove mentions\n",
    "    tweet = re.sub(r'@\\S+', '', tweet)\n",
    "    # remove punctuations\n",
    "    tweet = re.sub('[!\"#\\$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', '', tweet)\n",
    "    # remove extra whitespace\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    # remove extra whitespace\n",
    "    tweet = re.sub(r'\\s+$', '', tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "output = clean_tweet(tweet)\n",
    "\n",
    "assert output == desired_output, 'Not equal!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**© 2019 Data Science Institute of Australia**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-9_1-Answers.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

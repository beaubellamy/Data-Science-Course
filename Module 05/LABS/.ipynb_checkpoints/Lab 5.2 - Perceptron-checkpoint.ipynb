{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jq8zRd3jTtAb"
   },
   "source": [
    "![alt text](https://i.imgur.com/1WaY7aA.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ioFn-df0TtAd"
   },
   "source": [
    "# Lab 5.2 \n",
    "# *The Perceptron*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZrnRfDnTtAf"
   },
   "source": [
    "The perceptron is the basic unit of a neural network. It learns by adjusting the weights applied to each of its inputs until the error at its output is minimised.\n",
    "\n",
    "The example in this lab uses the stochastic gradient descent (SGD) algorithm to optimise the weights of a perceptron applied to a 2D classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zx6z5_xXTtAi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xr7oFCsUTtAp"
   },
   "source": [
    "The training dataset has 2 numeric features (X is 2D) and a binary response (y = +/-1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTGIf8aVTtAr"
   },
   "outputs": [],
   "source": [
    "X = np.array([[-2, 4], [4, 1], [1, 6], [2, 4], [6, 2]])\n",
    "y = np.array([-1, -1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mq1AisHdTtAx"
   },
   "source": [
    "Here is the training data, along with a candidate hyperplane that separates the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edayhuvQTtAz"
   },
   "outputs": [],
   "source": [
    "def plotData(X):\n",
    "    for d, sample in enumerate(X):\n",
    "        # Plot the negative samples\n",
    "        if d < 2:\n",
    "            plt.scatter(sample[0], sample[1], s = 120, marker = '_', color = 'blue', linewidths = 2)\n",
    "        # Plot the positive samples\n",
    "        else:\n",
    "            plt.scatter(sample[0], sample[1], s = 120, marker = '+', color = 'blue', linewidths = 2)\n",
    "    plt.xlabel('X0')\n",
    "    plt.ylabel('X1')\n",
    "\n",
    "plotData(X)\n",
    "\n",
    "# Print a possible hyperplane, that is seperating the two classes:\n",
    "plt.plot([-2, 6], [6, 0.5], color = 'orange', linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mC2tr-NzTtA2"
   },
   "source": [
    "The activation function is based on the dot product of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6cXLNCHTtA4"
   },
   "source": [
    "We need to include a bias term (-1) in the X array. This will transform the decision boundary so that the sign of the dot product of any data point with the weights vector (represented by ⟨x[i], w⟩ in code commments, below) will determine class membership: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kB2nAgFCTtA5"
   },
   "outputs": [],
   "source": [
    "X = np.array([ [-2, 4, -1], [4, 1, -1], [1, 6, -1], [2, 4, -1], [6, 2, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "osAbAN8uTtA9"
   },
   "source": [
    "Here is a simple implementation of the stochastic gradient descent algorithm for computing the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p19kSX3ATtA-"
   },
   "outputs": [],
   "source": [
    "def perceptron_sgd(Xt, Yt, eta = 1, epochs = 20):\n",
    "    \n",
    "    # Initialize the weight vector for the perceptron with zeros:\n",
    "    wt = np.zeros(len(Xt[0]))\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        \n",
    "        # Iterate over each sample in the data set:\n",
    "        for i, x in enumerate(Xt):\n",
    "            \n",
    "            # Test for misclassification: y * ⟨x[i], w⟩ <= 0:\n",
    "            if (np.dot(Xt[i], wt) * Yt[i]) <= 0:\n",
    "                \n",
    "                # Update weights:\n",
    "                wt = wt + eta * Xt[i] * Yt[i]\n",
    "\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0KLK06CTtBA"
   },
   "source": [
    "Compute the weights using default learning rate (eta = 1) and number of epochs = 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhnp-r5ZTtBB"
   },
   "outputs": [],
   "source": [
    "w = perceptron_sgd(X, y, epochs = 10)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-bVPkYmTtBE"
   },
   "source": [
    "Did it work? Let's check the decision boundary (hyperplane) and try some predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7mGWtPfTtBF"
   },
   "outputs": [],
   "source": [
    "def plotHyperplane(wt):\n",
    "    \n",
    "    # Nb. Plotting the hyperplance uses some complex tricks ...\n",
    "    \n",
    "    x2 = [wt[0], wt[1], -wt[1], wt[0]]\n",
    "    x3 = [wt[0], wt[1], wt[1], -wt[0]]\n",
    "    x2x3 = np.array([x2, x3])\n",
    "    # print(x2x3)\n",
    "    Xp, yp, U, V = zip(*x2x3)\n",
    "    # print(Xp, yp, U, V)\n",
    "    ax = plt.gca()\n",
    "    ax.quiver(Xp, yp, U, V, scale = 1, color = 'orange')\n",
    "    \n",
    "plotData(X)\n",
    "plotHyperplane(w)\n",
    "\n",
    "# Test samples:\n",
    "plt.scatter(2, 2, s = 120, marker = '_', linewidths = 2, color = 'red')\n",
    "plt.scatter(4, 3, s = 120, marker = '+', linewidths = 2, color = 'red')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UP9Ce-hxTtBH"
   },
   "source": [
    "So, not only is one of the new test points misclassified, one of the training points is also misclassified! \n",
    "\n",
    "Let's a look at how the model training actually proceeds. The error at each epoch is calculated using a hinge-loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj0rgwdWTtBI"
   },
   "outputs": [],
   "source": [
    "def perceptron_sgd_plot(Xt, Yt, eta = 1, epochs = 10):\n",
    "\n",
    "    wt = np.zeros(len(Xt[0]))\n",
    "    errors = []\n",
    "\n",
    "    for t in range(epochs):\n",
    "        total_error = 0\n",
    "        for i, x in enumerate(Xt):\n",
    "            if (np.dot(Xt[i], wt) * Yt[i]) <= 0:\n",
    "                total_error += (np.dot(Xt[i], wt) * Yt[i])\n",
    "                wt += eta * Xt[i] * Yt[i]\n",
    "        errors.append(total_error * (-1))\n",
    "        \n",
    "    plt.plot(errors)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Total Loss')\n",
    "    \n",
    "    return wt\n",
    "\n",
    "print(perceptron_sgd_plot(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQHKxWwPTtBL"
   },
   "source": [
    "So, 10 epochs clearly wasn't enough for the SGD algorithm to converge. \n",
    "\n",
    "Try a increasing `epochs` until the error goes to zero, then replot the test data and decision boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unHdQjgETtBL"
   },
   "outputs": [],
   "source": [
    "#?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gV9DO1-mTtBO"
   },
   "outputs": [],
   "source": [
    "#?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hp-B7PMATtBQ"
   },
   "source": [
    "Show how to manually compute class membership for a new data point Xi = [3.5, 3.3] using just the weights determined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AqWg7UDTtBR"
   },
   "outputs": [],
   "source": [
    "#?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8J6Os9kSTtBT"
   },
   "outputs": [],
   "source": [
    "#TEST: make sure the training data get correctly classified:\n",
    "\n",
    "#?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnscrVD3TtBU"
   },
   "source": [
    "## === End ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS5Tc4z9FoYy"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxI2We9OFpfs"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81DoNxN1FqGN"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2019 Data Science Institute of Australia\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab 5.2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

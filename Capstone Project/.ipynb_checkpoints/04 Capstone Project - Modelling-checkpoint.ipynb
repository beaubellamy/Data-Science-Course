{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Modelling\n",
    "\n",
    "We will build a class that will allow us to run the data through several regression models, including a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import pickle\n",
    "import pylab as plot\n",
    "params = {'legend.fontsize': 18}\n",
    "plot.rcParams.update(params)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import (AdaBoostRegressor,\n",
    "                                BaggingRegressor,\n",
    "                                ExtraTreesRegressor,\n",
    "                                GradientBoostingRegressor,\n",
    "                                IsolationForest,\n",
    "                                RandomForestRegressor,\n",
    "                                RandomTreesEmbedding)\n",
    "\n",
    "#from sklearn.ensemble import VotingRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.linear_model import (ARDRegression,\n",
    "                                    BayesianRidge,\n",
    "                                    ElasticNet,\n",
    "                                    ElasticNetCV,\n",
    "                                    HuberRegressor,\n",
    "                                    Lars,\n",
    "                                    LarsCV,\n",
    "                                    Lasso,\n",
    "                                    LassoCV,\n",
    "                                    LassoLars,\n",
    "                                    LassoLarsCV,\n",
    "                                    LassoLarsIC,\n",
    "                                    LinearRegression,\n",
    "                                    LogisticRegression,\n",
    "                                    LogisticRegressionCV,\n",
    "                                    MultiTaskLasso,\n",
    "                                    MultiTaskElasticNet,\n",
    "                                    MultiTaskLassoCV,\n",
    "                                    MultiTaskElasticNetCV,\n",
    "                                    OrthogonalMatchingPursuit,\n",
    "                                    OrthogonalMatchingPursuitCV,\n",
    "                                    PassiveAggressiveClassifier,\n",
    "                                    PassiveAggressiveRegressor,\n",
    "                                    Perceptron,\n",
    "                                    RANSACRegressor,\n",
    "                                    Ridge,\n",
    "                                    RidgeClassifier,\n",
    "                                    RidgeClassifierCV,\n",
    "                                    RidgeCV,\n",
    "                                    SGDClassifier,\n",
    "                                    SGDRegressor,\n",
    "                                    TheilSenRegressor,\n",
    "                                    enet_path,\n",
    "                                    lars_path,\n",
    "                                    lasso_path,\n",
    "                                    orthogonal_mp,\n",
    "                                    orthogonal_mp_gram,\n",
    "                                    ridge_regression)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Regression metrics\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Construction of a bikesales modelling class\n",
    "\n",
    "class bikeSales:\n",
    "    \n",
    "    # Initialise the class fields\n",
    "    def __init__(self):\n",
    "\n",
    "        self.file = 'clean_sport.csv'\n",
    "        self.df = None\n",
    "        self.scaled_df = None\n",
    "        self.model = {'Name': 'RidgeCV',\n",
    "                      'Model': RidgeCV(cv=5),\n",
    "                      'Features': [],\n",
    "                      'Score': 0}\n",
    "        \n",
    "    \n",
    "    \n",
    "    # read the data in\n",
    "    def read_data(self):\n",
    "        df = pd.read_csv(self.file,\n",
    "                         parse_dates=['First_Seen','Last_Seen','Last_Modified'], \n",
    "                         infer_datetime_format=True)\n",
    "        \n",
    "        df.drop(['Suburb','Postcode'], axis=1, inplace=True)\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # convert the categorical features to dummy variables\n",
    "    def add_dummy_variables(self, categorical_features=None):\n",
    "        \n",
    "        if (categorical_features == None):\n",
    "            categorical_features = self.df.select_dtypes(exclude='number').columns\n",
    "            \n",
    "        # ignore the URL feature when training\n",
    "        categorical_features = list(set(categorical_features) - set('URL'))\n",
    "\n",
    "        additional = pd.get_dummies(self.df[categorical_features])\n",
    "        self.df[additional.columns] = additional\n",
    "        \n",
    "        self.df.drop(categorical_features, axis=1, inplace=True)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # plot the prediction accuracy\n",
    "    def plot_accuracy_predictions(self, y_test, pred):\n",
    "        fig, ax = plt.subplots(figsize=(12,10))\n",
    "        ax.scatter(y_test,pred)\n",
    "        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=0.8)\n",
    "        ax.set_xlabel('Measured')\n",
    "        ax.set_ylabel('Predicted')\n",
    "        ax.set_title('Accuracy of Predictions')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # Optinally scale the data.\n",
    "    def scale_data(self, target='Price'):\n",
    "        local_df = self.df.select_dtypes(include='number')\n",
    "\n",
    "        features = list(set(local_df.columns) - set([target]))\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(self.df[features])\n",
    "        s = sc.transform(self.df[features])\n",
    "        self.scaled_df = pd.DataFrame(s,columns=features)\n",
    "\n",
    "        return None\n",
    "    \n",
    "    # Calculate the adjsuted R squared value\n",
    "    def adjusted_r2(self, r2, n, k):\n",
    "        if (n-k-1 == 0):\n",
    "            return r2\n",
    "        else:\n",
    "            return 1 - (1-r2)*((n-1)/(n-k-1))\n",
    "\n",
    "        \n",
    "    # Split the data in to dealer and private sets as the training and testing set.\n",
    "    def dealer_split_data(self,features):\n",
    "        \n",
    "        train = self.df[self.df['Seller_Dealer'] == 1]\n",
    "        test = self.df[self.df['Seller_Dealer'] == 0]\n",
    "\n",
    "        X_train, y_train = train[features], train['Price']\n",
    "        X_test, y_test = test[features], test['Price']\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    # split the data randomly into training and testing set.\n",
    "    def split_data(self, features, scaled=False, test_size=0.3, random_state=1):\n",
    "        \n",
    "        self.model['Features'] = features\n",
    "        X = self.df[features]\n",
    "        y = self.df['Price']\n",
    "        \n",
    "        if scaled == True:\n",
    "            X = self.scaled_df[features]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, test_size=test_size)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    # Search through multiple models for the best regression model. \n",
    "    def find_best_model(self, features, y, scaled=False):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.split_data(features)\n",
    "\n",
    "        best_score = 0\n",
    "        models = []\n",
    "        crossValidation=5\n",
    "        \n",
    "                \n",
    "        models.append((\"ARDRegression\",ARDRegression()))\n",
    "        models.append((\"BayesianRidge\",BayesianRidge()))\n",
    "        models.append((\"ElasticNet\",ElasticNet()))\n",
    "        models.append((\"ElasticNetCV\",ElasticNetCV(cv=crossValidation)))\n",
    "        models.append((\"Lars\",Lars()))\n",
    "        models.append((\"LarsCV\",LarsCV(cv=crossValidation)))\n",
    "        models.append((\"Lasso\",Lasso()))\n",
    "        models.append((\"LassoCV\",LassoCV(cv=crossValidation)))\n",
    "        models.append((\"LassoLars\",LassoLars()))\n",
    "        models.append((\"LassoLarsCV\",LassoLarsCV(cv=crossValidation)))\n",
    "        models.append((\"LassoLarsIC\",LassoLarsIC()))\n",
    "        models.append((\"LinearRegression\",LinearRegression()))\n",
    "        #models.append((\"LogisticRegression\",LogisticRegression()))\n",
    "        #models.append((\"LogisticRegressionCV\",LogisticRegressionCV(cv=crossValidation)))\n",
    "        models.append((\"OrthogonalMatchingPursuit\",OrthogonalMatchingPursuit()))\n",
    "        models.append((\"OrthogonalMatchingPursuitCV\",OrthogonalMatchingPursuitCV(cv=crossValidation)))\n",
    "        models.append((\"PassiveAggressiveClassifier\",PassiveAggressiveClassifier()))\n",
    "        models.append((\"PassiveAggressiveRegressor\",PassiveAggressiveRegressor()))\n",
    "        models.append((\"Perceptron\",Perceptron()))\n",
    "        models.append((\"Ridge\",Ridge()))\n",
    "        models.append((\"RidgeClassifier\",RidgeClassifier()))\n",
    "        models.append((\"RidgeClassifierCV\",RidgeClassifierCV(cv=crossValidation)))\n",
    "        models.append((\"RidgeCV\",RidgeCV(cv=crossValidation)))\n",
    "        models.append((\"SGDClassifier\",SGDClassifier()))\n",
    "        models.append((\"SGDRegressor\",SGDRegressor()))\n",
    "        \n",
    "        models.append((\"AdaBoostRegressor\",AdaBoostRegressor()))\n",
    "        models.append((\"BaggingRegressor\",BaggingRegressor()))\n",
    "        #models.append((\"ExtraTreesRegressor\",ExtraTreesRegressor()))\n",
    "        models.append((\"GradientBoostingRegressor\",GradientBoostingRegressor()))\n",
    "        #models.append((\"IsolationForest\",IsolationForest()))\n",
    "        models.append((\"RandomForestRegressor\",RandomForestRegressor()))\n",
    "        #models.append((\"RandomTreesEmbedding\",RandomTreesEmbedding()))\n",
    "        \n",
    "        n, k = X_train.shape\n",
    "\n",
    "        for name, model in models:\n",
    "            score = cross_val_score(model, X_train, y_train,  cv=5)\n",
    "            \n",
    "            print (name, score.mean())\n",
    "            if name == models[0][0]:\n",
    "                best_score = score.mean()\n",
    "            \n",
    "            if ((score.mean() > best_score) & (score.mean() <= 1)):\n",
    "                best_score = score.mean()\n",
    "                self.model['Name'] = name\n",
    "                self.model['Model'] = model\n",
    "                self.model['Score'] = score.mean()\n",
    "                \n",
    "        return None\n",
    "\n",
    "\n",
    "    def optimise_best_model(self):\n",
    "        \n",
    "        # Set the values for all possibilities of parameter tuning\n",
    "        n_iter=[100,300,500,1000]\n",
    "        max_iter = n_iter\n",
    "        alpha_1=[1e-8,1e-7,1e-6,1e-5,1e-4,1e-3]\n",
    "        alpha_2=[1e-8,1e-7,1e-6,1e-5,1e-4,1e-3]\n",
    "        lambda_1=[1e-8,1e-7,1e-6,1e-5,1e-4,1e-3]\n",
    "        lambda_2=[1e-8,1e-7,1e-6,1e-5,1e-4,1e-3]\n",
    "        fit_intercept=[True, False]\n",
    "        normalize=[True, False]\n",
    "        alphas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]\n",
    "        alpha = [0.1, 0.3, 0.5, 0.6, 0.75, 0.9, 0.95]\n",
    "        l1_ratio=[0,0.1,0.3,0.6,0.8,1.0]\n",
    "        n_nonzero_coefs=[100,300,500,800,1000,np.inf]\n",
    "        criterion = ['bic', 'aic']\n",
    "        penalty=['l1','l2','elasticnet'] \n",
    "        regularizationStrength=[1e-4,1e-3,1e-2,1e-1,1.0,10,100,1000]\n",
    "        solver=['auto','svd','cholesky','lsqr','sparse_cg','sag','saga']\n",
    "        learning_rate = [1e-3, 1e-2, 1e-1, 1.0]\n",
    "        n_estimators = [50,100,200,300,400,500]\n",
    "        loss = ['linear','square','exponential']\n",
    "        ensemble_loss = ['ls','lad','huber','quantile']\n",
    "        max_samples = [0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "        bootstrap = [True, False]\n",
    "        bootstrap_features = [True, False]\n",
    "        oob_score = [True, False]\n",
    "        criterion_split = ['mse','mae']\n",
    "        max_depth = [5, 10, 15, 20, 25, 50, 100, 200]\n",
    "        contamination = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "        l2_regularization = [0, 0.2, 0.5, 0.7, 0.9, 1.0]\n",
    "        max_bins = [10, 50, 100, 150, 200, 256]\n",
    "        \n",
    "        crossValidation=5\n",
    "\n",
    "        X_train, X_test, y_train, y_test = self.split_data(self.model['Features'])\n",
    "\n",
    "        \n",
    "        if self.model['Name'] in ['ARDRegression','BayesianRidge']:\n",
    "            \n",
    "            best = {'score': 0,\n",
    "                    'n_iter': 500,\n",
    "                    'alpha_1': 1e-6,\n",
    "                    'alpha_2': 1e-6,\n",
    "                    'lambda_1': 1e-4,\n",
    "                    'lambda_2': 1e-4,\n",
    "                    'fit_intercept': True,\n",
    "                    'normalize': True}\n",
    "\n",
    "            for n in n_iter:\n",
    "                for a1 in alpha_1:\n",
    "                    for a2 in alpha_2:\n",
    "                        for l1 in lambda_1:\n",
    "                            for l2 in lambda_2:\n",
    "                                for intercept in fit_intercept:\n",
    "                                    for norm in normalize:\n",
    "\n",
    "\n",
    "                                        if self.model['Name'] == 'ARDRegression':\n",
    "                                            model = ARDRegression(n_iter=n,alpha_1=a1,alpha_2=a2,lambda_1=l1,\n",
    "                                                                    lambda_2=l2,fit_intercept=intercept, normalize=norm)\n",
    "\n",
    "                                        if self.model['Name'] == 'BayesianRidge':\n",
    "                                            model = BayesianRidge(n_iter=n,alpha_1=a1,alpha_2=a2,lambda_1=l1,\n",
    "                                                                    lambda_2=l2,fit_intercept=intercept, normalize=norm)\n",
    "\n",
    "                                        model.fit(X_train, y_train)\n",
    "                                        score = model.score(X_train, y_train)\n",
    "\n",
    "                                        if score > best['score']:\n",
    "                                                best = {'score': score,\n",
    "                                                        'n_iter': n,\n",
    "                                                        'alpha_1': a1,\n",
    "                                                        'alpha_2': a2,\n",
    "                                                        'lambda_1': l1,\n",
    "                                                        'lambda_2': l2,\n",
    "                                                        'fit_intercept': intercept,\n",
    "                                                        'normalize': norm}\n",
    "                                                self.model['Model'] = model\n",
    "                                                self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] in ['ElasticNet','ElasticNetCV']:\n",
    "            \n",
    "            best = {'score': 0,\n",
    "                    'alpha': [0.5],\n",
    "                    'l1_ratio': 0.5,\n",
    "                    'fit_intercept':False,\n",
    "                    'normalize': True,\n",
    "                    'max_iter':300}\n",
    "\n",
    "            for a in alpha:\n",
    "                for l1 in l1_ratio:\n",
    "                    for intercept in fit_intercept:\n",
    "                        for norm in normalize:\n",
    "                            for iter_n in max_iter:\n",
    "\n",
    "                                if self.model['Name'] == 'ElasticNet':\n",
    "                                    model = ElasticNet(alpha=[a], l1_ratio=l1, fit_intercept=intercept, \n",
    "                                                       normalize=norm, max_iter=iter_n)\n",
    "\n",
    "                                if self.model['Name'] == 'ElasticNetCV':\n",
    "                                    model = ElasticNetCV(alpha=[a], l1_ratio=l1, fit_intercept=intercept, \n",
    "                                                         normalize=norm, max_iter=iter_n,cv=crossValidation)\n",
    "\n",
    "                                model.fit(X_train,y_train)\n",
    "                                score = model.score(X_train,y_train)\n",
    "\n",
    "                                if (score > best['score']):\n",
    "                                    best = {'score': score,\n",
    "                                            'alpha': [a],\n",
    "                                            'l1_ratio': l1,\n",
    "                                            'fit_intercept': intercept,\n",
    "                                            'normalize': norm,\n",
    "                                            'max_iter': iter_n}\n",
    "                                    self.model['Model'] = model\n",
    "                                    self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] == 'Lars':\n",
    "            \n",
    "            best = {'score': 0,\n",
    "                    'n_nonzero_coefs': 500,\n",
    "                    'fit_intercept': False,\n",
    "                    'normalize': True}\n",
    "\n",
    "\n",
    "            for intercept in fit_intercept:\n",
    "                for norm in normalize:\n",
    "                    for n_coef in n_nonzero_coefs:\n",
    "\n",
    "                        model = Lars(fit_intercept=intercept,normalize=norm,n_nonzero_coefs=n_coef)\n",
    "\n",
    "                        model.fit(X_train,y_train)\n",
    "                        score = model.score(X_train,y_train)\n",
    "\n",
    "                        if (score > best['score']):\n",
    "                            best = {'score': score,\n",
    "                                    'n_nonzero_coefs': n_coef,\n",
    "                                    'fit_intercept': intercept,\n",
    "                                    'normalize': norm}\n",
    "                            self.model['Model'] = model\n",
    "                            self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] == 'LarsCV':\n",
    "        \n",
    "            best = {'score': 0,\n",
    "                    'max_iter': 500,\n",
    "                    'fit_intercept': False,\n",
    "                    'normalize': True}\n",
    "\n",
    "            for intercept in fit_intercept:\n",
    "                for norm in normalize:\n",
    "                    for max_i in max_iter:\n",
    "\n",
    "                        model = LarsCV(fit_intercept=intercept,normalize=norm,max_iter=max_i,cv=crossValidation)\n",
    "\n",
    "                        model.fit(X_train,y_train)\n",
    "                        score = model.score(X_train,y_train)\n",
    "\n",
    "                        if (score > best['score']):\n",
    "                            best = {'score': score,\n",
    "                                    'max_iter': max_i,\n",
    "                                    'fit_intercept': intercept,\n",
    "                                    'normalize': norm}\n",
    "                            self.model['Model'] = model\n",
    "                            self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] in ['Lasso','LassoCV','LassoLars','LassoLarsCV']:\n",
    "\n",
    "            best = {'score': 0,\n",
    "                    'alpha': [0.5],\n",
    "                    'max_iter': 500,\n",
    "                    'fit_intercept': False,\n",
    "                    'normalize': True}\n",
    "\n",
    "            for a in alpha:\n",
    "                for intercept in fit_intercept:\n",
    "                    for norm in normalize:\n",
    "                        for max_i in max_iter:\n",
    "\n",
    "                            if self.model['Name'] == 'Lasso':\n",
    "                                model = Lasso(alpha=[a],fit_intercept=intercept,normalize=norm,max_iter=max_i)\n",
    "\n",
    "                            if self.model['Name'] == 'LassoCV':\n",
    "                                model = LassoCV(alpha=[a],fit_intercept=intercept,normalize=norm,max_iter=max_i,cv=crossValidation)\n",
    "\n",
    "                            if self.model['Name'] == 'LassoLars':\n",
    "                                model = LassoLars(alpha=[a],fit_intercept=intercept,normalize=norm,max_iter=max_i)\n",
    "\n",
    "                            if self.model['Name'] == 'LassoLarsCV':\n",
    "                                model = LassoLarsCV(alpha=[a],fit_intercept=intercept,normalize=norm,max_iter=max_i,cv=crossValidation)\n",
    "\n",
    "\n",
    "                            model.fit(X_train,y_train)\n",
    "                            score = model.score(X_train,y_train)\n",
    "\n",
    "                            if (score > best['score']):\n",
    "                                best = {'score': score,\n",
    "                                        'alpha': [a],\n",
    "                                        'fit_intercept': intercept,\n",
    "                                        'normalize': norm,\n",
    "                                        'max_iter': max_i}\n",
    "                                self.model['Model'] = model\n",
    "                                self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] == 'LassoLarsIC':\n",
    "\n",
    "            best = {'score': 0,\n",
    "                    'criterion': 'aic',\n",
    "                    'alpha': [0.5],\n",
    "                    'max_iter': 500,\n",
    "                    'fit_intercept': False,\n",
    "                    'normalize': True}\n",
    "\n",
    "            for crit in criterion:\n",
    "                for a in alpha:\n",
    "                    for intercept in fit_intercept:\n",
    "                        for norm in normalize:\n",
    "                            for max_i in max_iter:\n",
    "\n",
    "                                model = LassoLarsIC(criterion=crit,alpha=[a],fit_intercept=intercept,\n",
    "                                                    normalize=norm,max_iter=max_i)\n",
    "\n",
    "                                model.fit(X_train,y_train)\n",
    "                                score = model.score(X_train,y_train)\n",
    "\n",
    "                                if (score > best['score']):\n",
    "                                    best = {'score': score,\n",
    "                                            'criterion': crit,\n",
    "                                            'alpha': [a],\n",
    "                                            'max_iter':max_i,\n",
    "                                            'fit_intercept': intercept,\n",
    "                                            'normalize': norm}\n",
    "                                    self.model['Model'] = model\n",
    "                                    self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] == 'LinearRegression':\n",
    "\n",
    "            best = {'score': 0,\n",
    "                    'fit_intercept': False,\n",
    "                    'normalize': True}\n",
    "\n",
    "            for intercept in fit_intercept:\n",
    "                for norm in normalize:\n",
    "\n",
    "                    model = LinearRegression(fit_intercept=intercept,normalize=norm)\n",
    "\n",
    "                    model.fit(X_train,y_train)\n",
    "                    score = model.score(X_train,y_train)\n",
    "\n",
    "                    if (score > best['score']):\n",
    "                        best = {'score': score,\n",
    "                                'fit_intercept': intercept,\n",
    "                                'normalize': norm}\n",
    "                        self.model['Model'] = model\n",
    "                        self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] in ['LogisticRegression','LogisticRegressionCV']:\n",
    "\n",
    "            best = {'score': 0,\n",
    "                    'penalty': 'l2',\n",
    "                    'max_iter': 500,\n",
    "                    'fit_intercept': False,\n",
    "                    'C': 1.0}\n",
    "\n",
    "            for p in penalty:\n",
    "                for intercept in fit_intercept:\n",
    "                    for max_i in max_iter:\n",
    "                        for c in C:\n",
    "\n",
    "                            if self.model['Name'] == 'LogisticRegression':\n",
    "                                model = LogisticRegression(penalty=p,fit_intercept=intercept,max_iter=max_i,C=c)\n",
    "\n",
    "                            if self.model['Name'] == 'LogisticRegressionCV':\n",
    "                                model = LogisticRegressionCV(penalty=p,fit_intercept=intercept,max_iter=max_i,C=c,cv=crossValidation)\n",
    "\n",
    "                            model.fit(X_train,y_train)\n",
    "                            score = model.score(X_train,y_train)\n",
    "\n",
    "                            if (score > best['score']):\n",
    "                                best = {'score': score,\n",
    "                                        'penalty': p,\n",
    "                                        'fit_intercept': intercept,\n",
    "                                        'max_iter': max_i,\n",
    "                                        'C':c}\n",
    "                                self.model['Model'] = model\n",
    "                                self.model['score'] = score\n",
    "\n",
    "\n",
    "        if self.model['Name'] in ['OrthogonalMatchingPursuit','OrthogonalMatchingPursuitCV']:\n",
    "\n",
    "            best = {'score': 0,\n",
    "                    'n_nonzero_coefs': None,\n",
    "                    'fit_intercept': False,\n",
    "                    'normalize': True}\n",
    "\n",
    "            for n_coefs in n_nonzero_coefs:\n",
    "                for intercept in fit_intercept:\n",
    "                    for norm in normalize:\n",
    "\n",
    "                        if self.model['Name'] == 'OrthogonalMatchingPursuit':\n",
    "                            model = OrthogonalMatchingPursuit(n_nonzero_coefs=n_coefs,fit_intercept=intercept,\n",
    "                                                              normalize=norm)\n",
    "\n",
    "                        if self.model['Name'] == 'OrthogonalMatchingPursuitCV':\n",
    "                            model = OrthogonalMatchingPursuitCV(n_nonzero_coefs=n_coefs,fit_intercept=intercept,\n",
    "                                                              normalize=norm,cv=crossValidation)\n",
    "\n",
    "                        model.fit(X_train,y_train)\n",
    "                        score = model.score(X_train,y_train)\n",
    "\n",
    "                        if (score > best['score']):\n",
    "                            best = {'score': score,\n",
    "                                    'n_nonzero_coefs': n_coefs,\n",
    "                                    'fit_intercept': intercept,\n",
    "                                    'normalize': norm}\n",
    "                            self.model['Model'] = model\n",
    "                            self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] in ['PassiveAggressiveClassifier','PassiveAggressiveRegressor']:\n",
    "\n",
    "            best = {'score': 0,\n",
    "                    'max_iter': 500,\n",
    "                    'fit_intercept': False,\n",
    "                    'C': 1.0}\n",
    "\n",
    "            for max_i in max_iter:\n",
    "                for intercept in fit_intercept:\n",
    "                    for c in regularizationStrength:\n",
    "\n",
    "                        if self.model['Name'] == 'PassiveAggressiveClassifier':\n",
    "                            model = PassiveAggressiveClassifier(max_iter=max_i,fit_intercept=intercept,C=c)\n",
    "\n",
    "                        if self.model['Name'] == 'PassiveAggressiveRegressor':\n",
    "                            model = PassiveAggressiveRegressor(max_iter=max_i,fit_intercept=intercept,C=c)\n",
    "\n",
    "                        model.fit(X_train,y_train)\n",
    "                        score = model.score(X_train,y_train)\n",
    "\n",
    "                        if (score > best['score']):\n",
    "                            best = {'score': score,\n",
    "                                    'max_iter': max_i,\n",
    "                                    'fit_intercept': intercept,\n",
    "                                    'C': c}\n",
    "                            self.model['Model'] = model\n",
    "                            self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] == 'Perceptron':\n",
    "            \n",
    "            best = {'score': 0,\n",
    "                    'penalty': 'l2',\n",
    "                    'max_iter': 500,\n",
    "                    'fit_intercept': False,\n",
    "                    'alpha': 1.0}\n",
    "\n",
    "            for p in penalty:\n",
    "                for intercept in fit_intercept:\n",
    "                    for max_i in max_iter:\n",
    "                        for a in alpha:\n",
    "\n",
    "                            model = Perceptron(penalty=p,alpha=a,fit_intercept=intercept,max_iter=max_i,C=c)\n",
    "\n",
    "                            model.fit(X_train,y_train)\n",
    "                            score = model.score(X_train,y_train)\n",
    "\n",
    "                            if (score > best['score']):\n",
    "                                best = {'score': score,\n",
    "                                        'penalty': p,\n",
    "                                        'fit_intercept': intercept,\n",
    "                                        'max_iter': max_i,\n",
    "                                        'C':c}\n",
    "                                self.model['Model'] = model\n",
    "                                self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] in ['Ridge','RidgeClassifier']:\n",
    "\n",
    "            best = {'score': 0, \n",
    "                    'alpha': 0.1,\n",
    "                    'fit_intercept': True,\n",
    "                    'normalize': False,\n",
    "                    'solver': 'auto'}\n",
    "\n",
    "            for a in alpha:\n",
    "                for intercept in fit_intercept:\n",
    "                    for norm in normalize:\n",
    "                        for solve in solver:\n",
    "\n",
    "                            if self.model['Name'] == 'Ridge':\n",
    "                                model = Ridge(alpha=[a], fit_intercept=intercept, normalize=norm, solver=solve)\n",
    "\n",
    "                            if self.model['Name'] == 'RidgeClassifier':\n",
    "                                model = RidgeClassifier(alphas=[a], fit_intercept=intercept, normalize=norm, solver=solve)\n",
    "\n",
    "\n",
    "                                model = RidgeClassifier(alpha=[a], fit_intercept=intercept, normalize=norm, solver=solve)\n",
    "                            \n",
    "                            model.fit(X_train, y_train)\n",
    "                            score = model.score(X_train, y_train)\n",
    "\n",
    "                            if score > best['score']:\n",
    "                                best = {'score': score, \n",
    "                                        'alpha': [a],\n",
    "                                        'fit_intercept': intercept,\n",
    "                                        'normalize': norm,\n",
    "                                        'solver': solve}\n",
    "                                self.model['Model'] = model\n",
    "                                self.model['score'] = score\n",
    "       \n",
    "        if self.model['Name'] in ['RidgeCV','RidgeClassifierCV']:\n",
    "\n",
    "            best = {'score': 0, \n",
    "                    'alpha': 0.1,\n",
    "                    'fit_intercept': True,\n",
    "                    'normalize': False}\n",
    "\n",
    "            for a in alphas:\n",
    "                for intercept in fit_intercept:\n",
    "                    for norm in normalize:\n",
    "                                  \n",
    "                        if self.model['Name'] == 'RidgeCV':\n",
    "                            model = RidgeCV(alphas=[a], fit_intercept=intercept, normalize=norm, solver=solve, cv=crossValidation)\n",
    "\n",
    "                        if self.model['Name'] == 'RidgeClassifierCV':\n",
    "                            model = RidgeClassifierCV(alphas=[a], fit_intercept=intercept, normalize=norm, solver=solve, cv=crossValidation)\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        score = model.score(X_train, y_train)\n",
    "\n",
    "                        if score > best['score']:\n",
    "                            best = {'score': score, \n",
    "                                    'alpha': [a],\n",
    "                                    'fit_intercept': intercept,\n",
    "                                    'normalize': norm}\n",
    "                            self.model['Model'] = model\n",
    "                            self.model['score'] = score\n",
    "                                \n",
    "        if self.model['Name'] in ['RidgeCV','RidgeClassifierCV']:\n",
    "\n",
    "            best = {'score': 0, \n",
    "                    'alpha': 0.1,\n",
    "                    'fit_intercept': True,\n",
    "                    'normalize': False}\n",
    "\n",
    "            for intercept in fit_intercept:\n",
    "                for norm in normalize:\n",
    "                    norma\n",
    "                    if self.model['Name'] == 'RidgeCV':\n",
    "                        model = RidgeCV(alpha=alphas, fit_intercept=intercept, normalize=norm, cv=crossValidation)\n",
    "\n",
    "                    if self.model['Name'] == 'RidgeClassifierCV':\n",
    "                        model = RidgeClassifierCV(alpha=alphas, fit_intercept=intercept, normalize=norm, cv=crossValidation)\n",
    "\n",
    "                    model.fit(X_train, y_train)\n",
    "                    score = model.score(X_train, y_train)\n",
    "\n",
    "                    if score > best['score']:\n",
    "                        best = {'score': score, \n",
    "                                'alpha': [a],\n",
    "                                'fit_intercept': intercept,\n",
    "                                'normalize': norm}\n",
    "                        self.model['Model'] = model\n",
    "                        self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] in ['SGDClassifier','SGDRegressor']:\n",
    "\n",
    "            best = {'score': 0, \n",
    "                    'penalty': 'l2',\n",
    "                    'alpha': 0.1,\n",
    "                    'l1_ratio': 0.5,\n",
    "                    'fit_intercept': True,\n",
    "                    'max_iter': 1000,\n",
    "                    'learning_rate': 'contant'}\n",
    "\n",
    "            for p in penalty:\n",
    "                for a in alphas:\n",
    "                    for l1 in l1_ratio:\n",
    "                        for intercept in fit_intercept:\n",
    "                            for max_i in max_iter:\n",
    "                                for learn in learning_rate:\n",
    "\n",
    "                                    if self.model['Name'] == 'SGDClassifier':\n",
    "                                        model = SGDClassifier(penalty=p, alphas=a, l1_ratio=l1, fit_intercept=intercept, max_iter=max_i, leanring_rate=learn)\n",
    "\n",
    "                                    if self.model['Name'] == 'SGDRegressor':\n",
    "                                        model = SGDRegressor(penalty=p, alphas=a, l1_ratio=l1, fit_intercept=intercept, max_iter=max_i, leanring_rate=learn)\n",
    "\n",
    "\n",
    "                                    model.fit(X_train, y_train)\n",
    "                                    score = model.score(X_train, y_train)\n",
    "\n",
    "                                    if score > best['score']:\n",
    "                                        best = {'score': score, \n",
    "                                                'penalty': p,\n",
    "                                                'alpha': a,\n",
    "                                                'l1_ratio': l1,\n",
    "                                                'fit_intercept': intercept,\n",
    "                                                'max_iter': max_i,\n",
    "                                                'learning_rate': learn}\n",
    "                                        self.model['Model'] = model\n",
    "                                        self.model['score'] = score\n",
    "                                       \n",
    "        if self.model['Name'] == 'AdaBoostRegressor':\n",
    "            \n",
    "            best = {'score': 0, \n",
    "                    'n_estimators': 100,\n",
    "                    'loss': 'linear',\n",
    "                    'learning_rate': 1.0}\n",
    "\n",
    "            for n in n_estimators:\n",
    "                for loss in loss:\n",
    "                    for learn in learning_rate:\n",
    "\n",
    "                        model = AdaBoostRegressor(n_estimators=n, loss=loss, learning_rate=learn)\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        score = model.score(X_train, y_train)\n",
    "\n",
    "                        if score > best['score']:\n",
    "                            best = {'score': score, \n",
    "                                    'n_estimators': n,\n",
    "                                    'loss': loss,\n",
    "                                    'learning_rate': learn}\n",
    "                            self.model['Model'] = model\n",
    "                            self.model['score'] = score\n",
    "\n",
    "        if self.model['Name'] == 'BaggingRegressor':\n",
    "            \n",
    "            best = {'score': 0, \n",
    "                    'n_estimators': 100,\n",
    "                    'max_samples': 1.0,\n",
    "                    'bootstrap': False,\n",
    "                    'bootstrap_features': False,\n",
    "                    'oob_score': False}\n",
    "\n",
    "            for n in n_estimators:\n",
    "                for samples in max_samples:\n",
    "                    for boot in bootstrap:\n",
    "                        for boot_F in bootstrap_features:\n",
    "                            for oob in oob_score:\n",
    "\n",
    "                                model = BaggingRegressor(n_estimators=n, max_samples=samples, bootstrap=boot,\n",
    "                                                        bootstrap_features=boot_F, oob_score=oob)\n",
    "\n",
    "                                model.fit(X_train, y_train)\n",
    "                                score = model.score(X_train, y_train)\n",
    "\n",
    "                                if score > best['score']:\n",
    "                                    best = {'score': score, \n",
    "                                            'n_estimators': n,\n",
    "                                            'max_samples': samples,\n",
    "                                            'bootstrap': boot,\n",
    "                                            'bootstrap_features': boot_F,\n",
    "                                            'oob_score': oob}\n",
    "                                    self.model['Model'] = model\n",
    "                                    self.model['score'] = score\n",
    "        \n",
    "        if self.model['Name'] in ['ExtraTreesRegressor','RandomForestRegressor','RandomTreesEmbedding']:\n",
    "\n",
    "            best = {'score': 0, \n",
    "                    'n_estimators': 300,\n",
    "                    'criterion': 'mse',\n",
    "                    'max_depth': 50,\n",
    "                    'bootstrap': False,\n",
    "                    'oob_score': False}\n",
    "\n",
    "            for n in n_estimators:\n",
    "                for split in criterion_split:\n",
    "                    for depth in max_depth:\n",
    "                        for boot in bootstrap:\n",
    "                            for oob in oob_score:\n",
    "                                \n",
    "                                    if self.model['Name'] == 'ExtraTreesRegressor':\n",
    "                                        model = ExtraTreesRegressor(n_estimators=n,criterion=split,max_depth=depth,\n",
    "                                                                   bootstrap=boot, oob_score=oob)\n",
    "\n",
    "                                    if self.model['Name'] == 'RandomForestRegressor':\n",
    "                                        model = RandomForestRegressor(n_estimators=n,criterion=split,max_depth=depth,\n",
    "                                                                   bootstrap=boot, oob_score=oob)\n",
    "\n",
    "                                    if self.model['Name'] == 'RandomTreesEmbedding':\n",
    "                                        model = RandomTreesEmbedding(n_estimators=n,criterion=split,max_depth=depth,\n",
    "                                                                   bootstrap=boot, oob_score=oob)\n",
    "\n",
    "                                    model.fit(X_train, y_train)\n",
    "                                    score = model.score(X_train, y_train)\n",
    "\n",
    "                                    if score > best['score']:\n",
    "                                        best = {'score': score, \n",
    "                                                'n_estimators': n,\n",
    "                                                'criterion': split,\n",
    "                                                'max_depth': depth,\n",
    "                                                'bootstrap': boot,\n",
    "                                                'oob_score': oob}\n",
    "                                        self.model['Model'] = model\n",
    "                                        self.model['score'] = score\n",
    "        \n",
    "        if self.model['Name'] == 'GradientBoostingRegressor':\n",
    "            \n",
    "            best = {'score': 0, \n",
    "                    'loss': 'ls',\n",
    "                    'learning_rate': 1.0,\n",
    "                    'n_estimators': 300,\n",
    "                    'criterion': 'mse',\n",
    "                    'max_depth': 50,\n",
    "                    'alpha': 0.5}\n",
    "\n",
    "            for loss in ensemble_loss:\n",
    "                print (loss)\n",
    "                for learn in learning_rate:\n",
    "                    print ('  ',learn)\n",
    "                    for n in n_estimators:\n",
    "                        for split in criterion_split:\n",
    "                            for depth in max_depth:\n",
    "                                for a in alpha:\n",
    "\n",
    "                                    model = GradientBoostingRegressor(loss=loss,learning_rate=learn, n_estimators=n,\n",
    "                                                                     criterion=split, max_depth=depth, alpha=a)\n",
    "\n",
    "                                    model.fit(X_train, y_train)\n",
    "                                    score = model.score(X_train, y_train)\n",
    "\n",
    "                                    if score > best['score']:\n",
    "                                        best = {'score': score, \n",
    "                                                'loss': loss,\n",
    "                                                'learning_rate': learn,\n",
    "                                                'n_estimators': n,\n",
    "                                                'criterion': split,\n",
    "                                                'max_depth': depth,\n",
    "                                                'alpha': a}\n",
    "                                        self.model['Model'] = model\n",
    "                                        self.model['score'] = score\n",
    "        \n",
    "        if self.model['Name'] == 'IsolationForest':\n",
    "            \n",
    "            best = {'score': 0, \n",
    "                    'contamination': 0.1,\n",
    "                    'bootstrap': False,\n",
    "                    'n_estimators': 300}\n",
    "\n",
    "            for cont in contamination:\n",
    "                for boot in bootstrap:\n",
    "                    for n in n_estimators:\n",
    "\n",
    "                        model = IsolationForest(contamination=cont,bootstrap=boot, n_estimators=n)\n",
    "\n",
    "                        model.fit(X_train, y_train)\n",
    "                        score = model.score(X_train, y_train)\n",
    "\n",
    "                        if score > best['score']:\n",
    "                            best = {'score': score, \n",
    "                                    'contamination': cont,\n",
    "                                    'bootstrap': boot,\n",
    "                                    'n_estimators': n}\n",
    "                            self.model['Model'] = model\n",
    "                            self.model['score'] = score\n",
    "\n",
    "#         if self.model['Name'] == 'VotingRegressor':\n",
    "            \n",
    "#             best = {'score': 0,\n",
    "#                     'n_estimators': 300}\n",
    "\n",
    "#             for n in n_estimators:\n",
    "\n",
    "#                 model = VotingRegressor(n_estimators=n)\n",
    "\n",
    "#                 model.fit(X_train, y_train)\n",
    "#                 score = model.score(X_train, y_train)\n",
    "\n",
    "#                 if score > best['score']:\n",
    "#                     best = {'score': score,\n",
    "#                             'n_estimators': n}\n",
    "#                     self.model['Model'] = model\n",
    "                                \n",
    "                                \n",
    "        \n",
    "#         if self.model['Name'] == 'HistGradientBoostingRegressor':\n",
    "            \n",
    "#             best = {'score': 0, \n",
    "#                     'learning_rate': 1.0,\n",
    "#                     'max_iter': 300,\n",
    "#                     'l2_regularization': 0.0,\n",
    "#                     'max_bins': 256}\n",
    "\n",
    "#             for learn in learning_rate:\n",
    "#                 for max_i in max_iter:\n",
    "#                     for l2 in l2_regularization:\n",
    "#                         for bins in max_bins:\n",
    "                            \n",
    "#                             model = HistGradientBoostingRegressor(learning_rate=learn,max_iter=max_i, \n",
    "#                                                                  l2_regularization=l2, max_bins=bins)\n",
    "                            \n",
    "#                             model.fit(X_train, y_train)\n",
    "#                             score = model.score(X_train, y_train)\n",
    "\n",
    "#                             if score > best['score']:\n",
    "#                                 best = {'score': score, \n",
    "#                                         'learning_rate': learn,\n",
    "#                                         'max_iter': max_i,\n",
    "#                                         'l2_regularization': l2,\n",
    "#                                         'max_bins': bins}\n",
    "#                                 self.model['Model'] = model\n",
    "                                \n",
    "        \n",
    "        print (best)\n",
    "            \n",
    "        \n",
    "        return\n",
    "    \n",
    "    # Recalculate the r squared score\n",
    "    def re_score(self):\n",
    "        r2 = self.model['Model'].score(self.df[self.model['Features']], self.df['Price'])\n",
    "        n, k = self.df[self.model['Features']].shape\n",
    "        \n",
    "        score = self.adjusted_r2(r2,n,k) \n",
    "        self.model['Score'] = score\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    # Select the features using forward feature selection\n",
    "    def feature_selection(self, features):\n",
    "\n",
    "        target = 'Price'\n",
    "        \n",
    "        X = self.df[features]\n",
    "        y = self.df[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)\n",
    "\n",
    "        # start with no predictors\n",
    "        included = []\n",
    "        # keep track of model and parameters\n",
    "        best = {'feature': '', 'r2': 0, 'a_r2': 0}\n",
    "        # create a model object to hold the modelling parameters\n",
    "        model = self.model['Model'] \n",
    "        # get the number of cases in the test data\n",
    "        n = X_test.shape[0]\n",
    "\n",
    "        while True:\n",
    "            changed = False\n",
    "\n",
    "            # list the features to be evaluated\n",
    "            excluded = list(set(features) - set(included))\n",
    "\n",
    "            # for each remaining feature to be evaluated\n",
    "            for new_column in excluded:\n",
    "\n",
    "                # fit the model with the Training data\n",
    "                fit = model.fit(X_train[included + [new_column]], y_train) # fit a model; consider which predictors should be included\n",
    "                # calculate the score (R^2 for Regression)\n",
    "                r2 = model.score(X_test[included + [new_column]], y_test) # calculate the score\n",
    "                # number of predictors in this model\n",
    "                k = len(included + [new_column]) + 1\n",
    "                # calculate the adjusted R^2\n",
    "                adjusted_r = self.adjusted_r2(r2,n,k) \n",
    "\n",
    "                # if model improves\n",
    "                if adjusted_r > best['a_r2']:\n",
    "                    # record new parameters\n",
    "                    best = {'feature': new_column, 'r2': r2, 'a_r2': adjusted_r}\n",
    "                    # flag that found a better model\n",
    "                    changed = True\n",
    "\n",
    "            # if found a better model after testing all remaining features\n",
    "            if changed:\n",
    "                # update control details\n",
    "                included.append(best['feature'])\n",
    "                excluded = list(set(excluded) - set(best['feature']))\n",
    "                print(f'Added feature: {best[\"feature\"]} with adjusted R^2 = {best[\"a_r2\"]:.3}')\n",
    "            else:\n",
    "                # terminate if no better model\n",
    "                break\n",
    "\n",
    "        self.model['Features'] = included\n",
    "        self.model['Score'] = best['a_r2']\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    # Alternative approach at forward feature selection\n",
    "    def feature_selection2(self, feature_set):\n",
    "                         \n",
    "        target = 'Price'\n",
    "        \n",
    "        model = self.model['Model'] \n",
    "\n",
    "        X = self.df[feature_set]\n",
    "        y = self.df[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)\n",
    "\n",
    "        n = X_train.shape[0]\n",
    "\n",
    "        best_score = 0\n",
    "        best_feature = ''\n",
    "        included = []\n",
    "\n",
    "        # top 10 features\n",
    "        while True:\n",
    "            changed = False\n",
    "\n",
    "            for col in feature_set:\n",
    "\n",
    "                model.fit(X_train[included + [col]], y_train)\n",
    "                r2 = model.score(X_test[included + [col]], y_test)\n",
    "\n",
    "                k = len(included + [col]) + 1\n",
    "                score = self.adjusted_r2(r2,n,k) \n",
    "\n",
    "                if (score > best_score):\n",
    "                    best_score = score\n",
    "                    best_feature = col\n",
    "                    changed = True\n",
    "\n",
    "\n",
    "            if changed:\n",
    "                included.append(best_feature)\n",
    "                print (f'ADDED: {best_feature}; score: {best_score:.3f}')\n",
    "                # reset for the next round\n",
    "                #best_score = 0\n",
    "                #best_feature = ''\n",
    "                feature_set = list(set(feature_set) - set(included))\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        self.model['Features'] = included\n",
    "        self.model['Score'] = best_score\n",
    "\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Fit the model\n",
    "    def fit(self, X, y):\n",
    "        self.model['Model'].fit(X, y)\n",
    "        return None\n",
    "        \n",
    "    # Predict using the model\n",
    "    def predict(self, X):\n",
    "        return self.model['Model'].predict(X)\n",
    "    \n",
    "    # Create a feature describing the type of deal based on the ratio \n",
    "    # of predicted price to sale price.\n",
    "    def deal_type(self):\n",
    "                      \n",
    "        self.df['Price_ratio'] = self.df['Price'] / self.df['Predicted_Price']\n",
    "\n",
    "        self.df['Deal_type'] = 'Dont Bother'\n",
    "        self.df['Deal_type'][self.df['Price_ratio'] < 0.9] = 'Negotiate'\n",
    "        self.df['Deal_type'][self.df['Price_ratio'] < 0.8] = 'Good Deal'\n",
    "        self.df['Deal_type'][self.df['Price_ratio'] < 0.75] = 'Great Deal'        \n",
    "        self.df['Deal_type'][self.df['Price_ratio'] < 0.5] = 'Its a steal'\n",
    "                \n",
    "        return None\n",
    "        \n",
    "    # diplay the predicted price and sale price using the deal type feature \n",
    "    # to distinguish a good deal.\n",
    "    def plot_deals(self,x,y,title='',figsize=(12,10)):\n",
    "                      \n",
    "        negotiate = self.df[self.df['Deal_type'] == 'Negotiate']\n",
    "        good = self.df[self.df['Deal_type'] == 'Good Deal']\n",
    "        great = self.df[self.df['Deal_type'] == 'Great Deal']\n",
    "        steal = self.df[self.df['Deal_type'] == 'Its a steal']\n",
    "\n",
    "        ax = plt.figure(figsize=figsize)\n",
    "        \n",
    "        sns.scatterplot(x=x,y=y,data=self.df,color='black',alpha=0.3);\n",
    "        sns.scatterplot(x=x,y=y,data=negotiate,label='Negotiate');\n",
    "        sns.scatterplot(x=x,y=y,data=good,label='Good Deal');\n",
    "        sns.scatterplot(x=x,y=y,data=great,label='Great Deal');\n",
    "        sns.scatterplot(x=x,y=y,data=steal,label='Its a steal');\n",
    "        ax = sns.lineplot(x=[self.df[x].min(),self.df[x].max()], \n",
    "                          y=[self.df[x].min(),self.df[x].max()],\n",
    "                          linewidth=1, alpha=0.5, color='red')\n",
    "        ax.lines[0].set_linestyle(\"--\")\n",
    "\n",
    "        plt.title(title,fontsize=24)\n",
    "        plt.xlabel(x, fontsize=18)\n",
    "        plt.ylabel(y, fontsize=18)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "       \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Pipeline Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# sport = bikeSales()\n",
    "# sport.read_data()\n",
    "# sport.df.head()\n",
    "# sport.add_dummy_variables()\n",
    "# sport.df.columns\n",
    "\n",
    "# # Create a list of features for simple baseline models\n",
    "# brand_cols = [col for col in sport.df.columns if 'Brand' in col]\n",
    "# model_cols = [col for col in sport.df.columns if 'Model' in col]\n",
    "naive_feature = ['Kilometers','Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def run_pipeline(features=None, optimise=False):\n",
    "    \n",
    "    sport = bikeSales()\n",
    "    sport.read_data()\n",
    "    sport.add_dummy_variables()\n",
    "    \n",
    "    if (features == None):\n",
    "        features = list(set(sport.df.columns) - set(['Price']))\n",
    "        \n",
    "    # Ignore the URL feature\n",
    "    update_features = []\n",
    "    for feature in features:\n",
    "        if 'URL' not in feature:\n",
    "            update_features.append(feature)\n",
    "    features = update_features\n",
    "    \n",
    "    sport.find_best_model(features, sport.df['Price'])\n",
    "    print ('Model: ',sport.model['Model'])\n",
    "    print ('Score: ',sport.model['Score'])\n",
    "\n",
    "    print ('Feature selection process.')\n",
    "    sport.feature_selection(features)\n",
    "    print ('Score: ',sport.model['Score'])\n",
    "    \n",
    "    # Optimise model parameters\n",
    "    if optimise:\n",
    "        print ('Optimising model')\n",
    "        sport.optimise_best_model()\n",
    "    \n",
    "    # Fit the full model\n",
    "    sport.fit(sport.df[sport.model['Features']],sport.df['Price'])\n",
    "    sport.re_score()\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = sport.predict(sport.df[sport.model['Features']])\n",
    "    sport.df['Predicted_Price'] = predictions\n",
    "    \n",
    "    # Determine the deal type\n",
    "    sport.deal_type()\n",
    "\n",
    "    # Display the predicted deals\n",
    "    sport.plot_deals(x='Price',y='Predicted_Price',title='Great Deals on Motorbikes')\n",
    "    print (f\"Model score: {sport.model['Score']}\")\n",
    "    \n",
    "    return sport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Naive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "naive = run_pipeline(naive_feature, optimise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#naive.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "naive.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#brands = run_pipeline(brand_cols, optimise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#models = run_pipeline(model_cols, optimise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# To reduce processing time change optimise flag to false so the model \n",
    "# hyperparameters are not tuned.\n",
    "# optimise=False\n",
    "allFeatures = run_pipeline(optimise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeatures.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = 'pipeline_model.pkl'\n",
    "\n",
    "# Saving the objects:\n",
    "with open(pipeline, 'wb') as f:\n",
    "    pickle.dump(allFeatures, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def r_squared(y, y_pred):\n",
    "    res = y - y_pred\n",
    "    tot = y - y.mean()\n",
    "\n",
    "    r2 = 1 - res.dot(res) / tot.dot(tot)\n",
    "    return r2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "naive_r2 = r_squared(naive.df['Price'], naive.df['Predicted_Price'])\n",
    "#brands_r2 = r_squared(brands.df['Price'], brands.df['Predicted_Price'])\n",
    "#models_r2 = r_squared(models.df['Price'], models.df['Predicted_Price'])\n",
    "allFeatures_r2 = r_squared(allFeatures.df['Price'], allFeatures.df['Predicted_Price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print (f'r2 for all naive model: {naive_r2}')\n",
    "#print (f'r2 for all brands model: {brands_r2}')\n",
    "#print (f'r2 for all models model: {models_r2}')\n",
    "print (f'r2 for all features model: {allFeatures_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Alternate Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sport = bikeSales()\n",
    "sport.read_data()\n",
    "#sport.add_dummy_variables()\n",
    "\n",
    "df = sport.df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "@interact\n",
    "def Dealer_split_distribution(feature=df.columns):\n",
    "    \n",
    "    dealer = df[df['Seller'] == 'Dealer']\n",
    "    private = df[df['Seller'] != 'Dealer']\n",
    "\n",
    "    #column = set(list(sport.select_dtypes(exclude='number').columns)) - set(['Description'])\n",
    "    ax = plt.figure(figsize=(12,10))\n",
    "    \n",
    "    if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "        ax = sns.distplot(dealer[feature])\n",
    "        ax = sns.distplot(private[feature])\n",
    "\n",
    "        #plt.gcf().set_size_inches(10,10)\n",
    "        #ax.annotate(stats.pearsonr)\n",
    "        plt.legend(labels=['Dealer','Private'])\n",
    "    \n",
    "    else:\n",
    "        sns.countplot(x=feature, hue='Seller', data=df)\n",
    "\n",
    "        \n",
    "    plt.suptitle('Distribution for Seller Type',x=0.5,y=1.01,size=18)\n",
    "    plt.xlabel(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from scipy import stats\n",
    "\n",
    "@interact\n",
    "def plot_counts(x=df.select_dtypes(include='number'),\n",
    "                y=df.select_dtypes(include='number'),\n",
    "                hue=df.select_dtypes(exclude='number')):\n",
    "    \n",
    "    #column = set(list(sport.select_dtypes(exclude='number').columns)) - set(['Description'])\n",
    "    ax = plt.figure(figsize=(12,10))\n",
    "    correlation = df[x].corr(df['Price'])\n",
    "    ax = sns.scatterplot(x=x,y=y,hue=hue,data=df)\n",
    "    #plt.gcf().set_size_inches(10,10)\n",
    "    #ax.annotate(stats.pearsonr)\n",
    "    plt.suptitle('Relationship to '+x,x=0.5,y=1.01,size=18)\n",
    "    plt.xlabel(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Inferred Dealer valuation\n",
    "\n",
    "We will make the assumption that all dealers have a good idea of the true value of a motorbike, since they have mechanics and valuation experts available on staff. We can then build a model based on the dealer data to make predictions on the private sellers valuation.\n",
    "\n",
    "The accuracy of this model will be based on the accuracy of prediction the dealer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def run_dealer_pipeline(features=None,optimise=True):\n",
    "    \n",
    "    sport = bikeSales()\n",
    "    sport.read_data()\n",
    "    sport.add_dummy_variables()\n",
    "    \n",
    "    if (features == None):\n",
    "        features = list(set(sport.df.columns) - set(['Price']))\n",
    "        \n",
    "    # Ignore the URL feature\n",
    "    update_features = []\n",
    "    for feature in features:\n",
    "        if 'URL' not in feature:\n",
    "            update_features.append(feature)\n",
    "    features = update_features\n",
    "    dealer_X, dealer_y, private_X, private_y = sport.dealer_split_data(features)\n",
    "\n",
    "    # reset the df to the dealer seller data\n",
    "    original_df = sport.df\n",
    "    training_df = dealer_X\n",
    "    training_df['Price'] = dealer_y\n",
    "    sport.df = training_df\n",
    "    \n",
    "    sport.find_best_model(features, sport.df['Price'])\n",
    "    print ('Model: ',sport.model['Model'])\n",
    "    print ('Score: ',sport.model['Score'])\n",
    "\n",
    "    print ('Feature selection process.')\n",
    "    sport.feature_selection(features)\n",
    "    print ('Score: ',sport.model['Score'])\n",
    "    \n",
    "    # Optimise model parameters\n",
    "    if optimise:\n",
    "        print ('Optimising model')\n",
    "        sport.optimise_best_model()\n",
    "    \n",
    "    # Fit the full model (all dealer data)\n",
    "    sport.fit(sport.df[sport.model['Features']],sport.df['Price'])\n",
    "    sport.re_score()\n",
    "    \n",
    "    # Reset the dataframe back to the dealer and private seller data\n",
    "    sport.df = original_df\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = sport.predict(sport.df[sport.model['Features']])\n",
    "    sport.df['Predicted_Price'] = predictions\n",
    "    sport.model['Model'].score(sport.df[sport.model['Features']], sport.df['Price'])\n",
    "    \n",
    "    # Determine the deal type\n",
    "    sport.deal_type()\n",
    "\n",
    "    # Display the predicted deals\n",
    "    sport.plot_deals(x='Price',y='Predicted_Price',title='Great Deals on Motorbikes')\n",
    "    print (f\"Model score {sport.model['Score']}\")\n",
    "    \n",
    "    return sport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Dealer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dealer_model = run_dealer_pipeline(optimise=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dealer_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dealer_file = 'dealer_model.pkl'\n",
    "# Saving the objects:\n",
    "with open(dealer_file, 'wb') as f:\n",
    "    pickle.dump(dealer_model, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df = dealer_model.df[dealer_model.df['Seller_Dealer'] == 1]\n",
    "dealer_r2 = r_squared(df['Price'], df['Predicted_Price'])\n",
    "print (f'Dealer r2 score: {dealer_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "test_df = dealer_model.df.copy(deep=True)\n",
    "test_df.head()\n",
    "\n",
    "# Find the its a steal bikes\n",
    "#steal = test_df[test_df['Deal_Type'] == 'Its a steal']\n",
    "#value = steal['Predicted_Price'].max()\n",
    "\n",
    "#steal[steal['Predicted_Price'] == value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "source": [
    "# Neural Network\n",
    "Usinig a Neural Network model with the infered dealer valuation scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sport = bikeSales()\n",
    "sport.read_data()\n",
    "#sport.add_dummy_variables()\n",
    "\n",
    "df = sport.df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummy_variables(df, categorical_features=None):\n",
    "        \n",
    "    if (categorical_features == None):\n",
    "        categorical_features = df.select_dtypes(exclude='number').columns\n",
    "\n",
    "    # ignore the URL feature when training\n",
    "    categorical_features = list(set(categorical_features) - set('URL'))\n",
    "\n",
    "    additional = pd.get_dummies(df[categorical_features])\n",
    "    df[additional.columns] = additional\n",
    "\n",
    "    df.drop(categorical_features, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature describing the type of deal based on the ratio \n",
    "# of predicted price to sale price.\n",
    "def deal_type(df):\n",
    "\n",
    "    df['Price_ratio'] = df['Price'] / df['Predicted_Price']\n",
    "\n",
    "    df['Deal_type'] = 'Dont Bother'\n",
    "    df['Deal_type'][df['Price_ratio'] < 0.9] = 'Negotiate'\n",
    "    df['Deal_type'][df['Price_ratio'] < 0.8] = 'Good Deal'\n",
    "    df['Deal_type'][df['Price_ratio'] < 0.75] = 'Great Deal'        \n",
    "    df['Deal_type'][df['Price_ratio'] < 0.5] = 'Its a steal'\n",
    "\n",
    "    return df\n",
    "\n",
    "# diplay the predicted price and sale price using the deal type feature \n",
    "# to distinguish a good deal.\n",
    "def plot_deals(df, x, y, title='', figsize=(12,10)):\n",
    "\n",
    "    negotiate = df[df['Deal_type'] == 'Negotiate']\n",
    "    good = df[df['Deal_type'] == 'Good Deal']\n",
    "    great = df[df['Deal_type'] == 'Great Deal']\n",
    "    steal = df[df['Deal_type'] == 'Its a steal']\n",
    "\n",
    "    ax = plt.figure(figsize=figsize)\n",
    "\n",
    "    sns.scatterplot(x=x,y=y,data=df,color='black',alpha=0.3);\n",
    "    sns.scatterplot(x=x,y=y,data=negotiate,label='Negotiate');\n",
    "    sns.scatterplot(x=x,y=y,data=good,label='Good Deal');\n",
    "    sns.scatterplot(x=x,y=y,data=great,label='Great Deal');\n",
    "    sns.scatterplot(x=x,y=y,data=steal,label='Its a steal');\n",
    "    ax = sns.lineplot(x=[df[x].min(),df[x].max()], y=[df[x].min(),df[x].max()],\n",
    "                      linewidth=1, alpha=0.5, color='red')\n",
    "    ax.lines[0].set_linestyle(\"--\")\n",
    "    \n",
    "    plt.title(title,fontsize=24)\n",
    "    plt.xlabel(x, fontsize=18)\n",
    "    plt.ylabel(y, fontsize=18)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_dummy_variables(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = list(set(df.columns) - set(['Price']))\n",
    "\n",
    "# Ignore the URL features\n",
    "update_features = []\n",
    "for feature in features:\n",
    "    if 'URL' not in feature:\n",
    "        update_features.append(feature)\n",
    "features = update_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def dealer_split_data(df,features):\n",
    "        \n",
    "    train = df[df['Seller_Dealer'] == 1]\n",
    "    test = df[df['Seller_Dealer'] == 0]\n",
    "\n",
    "    X_train, y_train = train[features], train['Price']\n",
    "    X_test, y_test = test[features], test['Price']\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dealer_X, dealer_y, private_X, private_y = dealer_split_data(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dealer_X, dealer_y, random_state=1, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Find the best architecture for the neural network\n",
    "def run_neural_networks(X_train, X_test, y_train, y_test):\n",
    "    n_cols = X_train.shape[1]\n",
    "    hidden_layers = range(1,5)\n",
    "    nodes = [50,100,150,200,300,500]\n",
    "    \n",
    "    results = {'hidden_layers': [],\n",
    "               'nodes': [],\n",
    "               'score': []}\n",
    "    \n",
    "    for layer in hidden_layers:\n",
    "\n",
    "        for node in nodes:\n",
    "\n",
    "            model = Sequential()\n",
    "            \n",
    "            model.add(Dense(n_cols, activation = 'relu', input_shape = (n_cols, )))\n",
    "            \n",
    "            if layer == 1:\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                \n",
    "            if layer == 2:\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "            \n",
    "            if layer == 3:\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                \n",
    "            if layer == 4:\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "\n",
    "            if layer == 5:\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "                model.add(Dense(node, activation = 'relu'))\n",
    "\n",
    "            # Add the output layer\n",
    "            model.add(Dense(1, activation = 'linear'))\n",
    "            \n",
    "            model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mse'])\n",
    "\n",
    "            model.fit(X_train, y_train, validation_split = 0.25, batch_size = 20, epochs = 1000, verbose = 0)\n",
    "\n",
    "            score = model.evaluate(X_test, y_test, batch_size = 20)\n",
    "            \n",
    "            results['hidden_layers'].append(layer)\n",
    "            results['nodes'].append(node)\n",
    "            results['score'].append(score[1])\n",
    "            \n",
    "            print (results['score'])\n",
    "    \n",
    "    \n",
    "    return results    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "results = run_neural_networks(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Extract the features for the optimul architecture\n",
    "results_df = pd.DataFrame.from_dict(results)\n",
    "best = results_df[results_df['score'] == results_df['score'].min()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def neural_network(X,y,results):\n",
    "    \n",
    "    layer = results['hidden_layers'].values[0]\n",
    "    node = results['nodes'].values[0]\n",
    "    n_cols = X.shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(n_cols, activation = 'relu', input_shape = (n_cols, )))\n",
    "\n",
    "    if layer == 1:\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "\n",
    "    if layer == 2:\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "\n",
    "    if layer == 3:\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "\n",
    "    if layer == 4:\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "\n",
    "    if layer == 5:\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "        model.add(Dense(node, activation = 'relu'))\n",
    "\n",
    "    # Add the output layer\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mse'])\n",
    "    \n",
    "    model.fit(X, y, validation_split = 0.25, batch_size = 20, epochs = 1000, verbose = 0)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Run the optimal neural network\n",
    "model = neural_network(dealer_X,dealer_y,best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Make predictions on the dealer and private seller data\n",
    "df['Predicted_Price'] = model.predict(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Create data frames of the data seperately\n",
    "dealer_df = df[df['Seller_Dealer'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Calculate the R squared score from the full model\n",
    "neural_network_r2 = r_squared(dealer_df['Price'], dealer_df['Predicted_Price'])\n",
    "neural_network_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df = deal_type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deals(df, 'Price', 'Predicted_Price',title='Great Deals for Motorbikes (NN)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# allFeatures2_r2\n",
    "\n",
    "print ('Model Scores:\\n'\n",
    "       f'Linear regression model:           {allFeatures_r2}\\n'\n",
    "       f'Linear regression dealer scenario: {dealer_r2}\\n'\n",
    "       f'Neural Network dealer scenario:    {neural_network_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
